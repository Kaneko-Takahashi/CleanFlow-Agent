# 要件定義書 - CleanFlow Agent

## システム概要

### プロダクト名

CleanFlow Agent

### 目的

CSV データをアップロードし、AI エージェントが自動的にデータプロファイリングと前処理プランの生成・実行を行うツール。ユーザーは分類・回帰・クラスタリングなどのタスク種別とターゲット列を指定するだけで、適切な前処理ステップ（欠損補完・エンコード・スケーリングなど）を自動生成し、実行できる。

### 想定ユーザー

- データサイエンティスト
- 機械学習エンジニア
- データ分析初心者
- データ前処理の自動化を求める開発者

## 対応データ

- **形式**: CSV（カンマ区切り）
- **構造**:
  - 行 = サンプル（データポイント）
  - 列 = 特徴量（特徴変数）
- **制約**:
  - ファイルサイズ上限（初期は 100MB 程度を想定）
  - 文字エンコーディング: UTF-8 推奨（Shift-JIS 等も対応可能）

## 機能要件

### 認証機能

#### ユーザー登録

- メールアドレス + パスワードで新規ユーザー登録
- メールアドレスの重複チェック
- パスワード強度チェック（最低 8 文字以上など）
- 登録成功時に自動ログイン（オプション）

#### ログイン

- メールアドレス + パスワードでログイン
- ログイン成功時に JWT アクセストークンを発行
- トークンは Authorization ヘッダで送信

#### ログアウト

- トークンの無効化（MVP ではクライアント側で削除のみ）

### データセット管理機能

#### CSV アップロード

- ログイン中ユーザーのみアップロード可能
- ファイル選択・アップロード
- アップロード時にデータセット名を指定（デフォルトはファイル名）
- サーバー側でファイルを保存（ローカルストレージまたは DB）

#### データセット一覧

- ログイン中ユーザーが所有するデータセットのみ表示
- 表示項目：
  - データセット名
  - 行数
  - 列数
  - 作成日時
  - 詳細ボタン

#### データセット削除

- 自分のデータセットのみ削除可能
- 削除時にファイルと DB レコードを削除

### データプロファイリング機能

#### プロファイル生成

- データセットアップロード時に自動生成
- 各列の情報：
  - データ型（int, float, object, datetime 等）
  - 欠損値の数・欠損率
  - ユニーク値の数
  - 基本統計量（平均、中央値、標準偏差、最小値、最大値など）
  - カテゴリ変数の場合は頻度分布

#### プロファイル表示

- データセット詳細画面で表示
- テーブル形式で各列のプロファイルを一覧表示

### 前処理プラン生成機能

#### タスク種別指定

- 分類（Classification）
- 回帰（Regression）
- クラスタリング（Clustering）

#### ターゲット列指定

- タスク種別に応じてターゲット列を選択
- 分類・回帰の場合は必須、クラスタリングの場合は不要

#### AI エージェントによるプラン生成

- LLM（OpenAI GPT-4 等）を使用
- データプロファイルとタスク種別・ターゲット列を入力
- 前処理ステップを JSON 形式で生成：
  - ステップの順序（order）
  - ステップ名（name）
  - 説明（description）
  - 実行コード（code_snippet: pandas/scikit-learn）

#### 生成される前処理ステップの例

- 欠損値補完（平均値、中央値、最頻値、前後の値など）
- カテゴリ変数のエンコード（One-Hot Encoding、Label Encoding）
- 数値変数のスケーリング（StandardScaler、MinMaxScaler）
- 外れ値の処理
- 特徴量選択
- データ分割（train/test）

### プラン実行機能

#### プラン実行

- 生成された前処理プランを実行
- pandas/scikit-learn のコードを安全に実行
- 実行ログを記録

#### Before/After サマリ表示

- 実行前のデータ形状・統計量
- 実行後のデータ形状・統計量
- 各ステップの実行結果（成功/失敗、処理時間など）

### 前処理レシピの保存・再利用

#### プラン保存

- 生成されたプランをデータベースに保存
- プラン名を付与可能

#### プラン一覧

- ユーザーが作成したプランの一覧表示
- プラン名、作成日時、関連データセット名を表示

#### プラン再利用

- 保存されたプランを他のデータセットに適用（MVP では簡易版）

## 非機能要件

### セキュリティ

#### 認証の安全性

- パスワードはハッシュ化して保存（bcrypt 等を使用）
- JWT のシークレットキーは環境変数で管理
- トークンの有効期限設定（例: 24 時間）
- HTTPS 通信を推奨（本番環境）

#### データ分離

- ユーザー間でデータが混在しないよう、user_id で厳密に分離
- ファイルアクセス権限の適切な設定

### パフォーマンス

#### 応答時間

- ログイン: 1 秒以内
- CSV アップロード: ファイルサイズに依存（10MB で 5 秒以内）
- プロファイル生成: データセットサイズに依存（10 万行で 10 秒以内）
- プラン生成: LLM API 呼び出しを含むため 30 秒以内
- プラン実行: データセットサイズとステップ数に依存

#### スケーラビリティ

- 初期は単一サーバーで動作
- 将来的に複数インスタンス対応可能な設計

### 使用技術

#### バックエンド

- Python 3.10 以上
- FastAPI
- SQLite（開発時）、PostgreSQL（本番環境想定）
- pandas / scikit-learn（データ処理）
- JWT 認証（python-jose、passlib）

#### LLM 連携

- OpenAI API（GPT-4 等）
- または他の LLM API（Claude、Gemini 等）

### ログ・監視

#### ログ出力

- アプリケーションログ（INFO、WARNING、ERROR）
- アクセスログ（API 呼び出し）
- エラーログ（スタックトレース含む）

#### 監視項目

- API 応答時間
- エラー率
- LLM API 呼び出し回数・コスト

## 将来拡張

### フロントエンド連携

- Supabase / Vercel と連携したフロントエンド開発
- React / Next.js 等を使用した SPA
- リアルタイム更新（WebSocket 等）

### マルチテナント SaaS 化

- 組織・チーム機能
- データセットの共有機能
- プランの公開・共有
- サブスクリプションモデル

### 機能拡張

- より高度な前処理ステップ（特徴量エンジニアリング、次元削減等）
- 複数の LLM プロバイダー対応
- プランのバージョン管理
- 実行履歴の詳細分析
- データ可視化機能
- バッチ処理機能
